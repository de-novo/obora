# obora 가설 검증 가이드

> Phase 0: 코드 작성 전 수동 검증

---

## 1. 개발자 인터뷰 스크립트

### 대상
- 시니어 개발자 / 테크리드 5명
- AI 코딩 도구 사용 경험자 우선

### 질문 리스트

```
[스크리닝]
1. 평소 AI 코딩 도구를 얼마나 자주 사용하시나요?
   - 매일 / 주 3-4회 / 가끔 / 거의 안 함

[핵심 질문]
2. 중요한 기술 결정(아키텍처, 라이브러리 선택 등)을 할 때
   AI에게 물어본 적 있으신가요?
   - 있다 → (구체적 사례?)
   - 없다 → (왜?)

3. 그런 결정을 할 때, 여러 AI(ChatGPT, Claude, Gemini)에게
   각각 물어보고 비교해본 적 있으신가요?
   - 있다 → (얼마나 자주? 도움이 됐나요?)
   - 없다 → (왜? 귀찮아서? 필요 없어서?)

4. 만약 "여러 AI에게 동시에 물어보고,
   서로 토론시킨 뒤 종합 리포트를 주는 도구"가 있다면
   쓸 의향이 있으신가요?
   - 꼭 쓰겠다 / 관심 있다 / 별로 / 전혀

5. 그런 도구에 얼마까지 지불하실 의향이 있으신가요?
   - $0 (무료만) / $10/월 / $30/월 / $50+/월

[추가 탐색]
6. AI 코딩 도구의 가장 큰 불만은 무엇인가요?

7. "AI가 틀렸는데 확신에 차 있어서 그대로 따랐다가
    문제가 생긴 경험"이 있으신가요?

8. 어떤 유형의 문제에서 AI의 답변을 가장 신뢰하기 어려우신가요?
```

### 성공 기준
| 질문 | 긍정 응답 기준 |
|------|---------------|
| Q3 (비교 경험) | 5명 중 2명 이상 "해봤다" |
| Q4 (사용 의향) | 5명 중 3명 이상 "관심 있다" 이상 |
| Q5 (지불 의향) | 5명 중 2명 이상 "$10/월" 이상 |

---

## 2. 수동 시뮬레이션 프로토콜

### 목적
obora가 자동화할 과정을 수동으로 수행하여 가치 확인

### 테스트 케이스 5개

#### Case 1: 아키텍처 의사결정
```
질문: "5명 팀에서 e-commerce 플랫폼을 새로 만들려고 합니다.
마이크로서비스 vs 모놀리스 중 어떤 것을 추천하시나요?
향후 3년간 MAU 100만 목표입니다."

평가 포인트:
- 각 AI가 다른 관점을 제시하는가?
- 한 AI가 놓친 리스크를 다른 AI가 잡아내는가?
- 종합하면 단일 AI 답변보다 풍부한가?
```

#### Case 2: 보안 취약점 분석
```
질문: [실제 코드 스니펫 첨부]
"이 결제 로직에서 보안 취약점이 있을까요?"

평가 포인트:
- 서로 다른 취약점을 발견하는가?
- 한 AI의 오탐(false positive)을 다른 AI가 교정하는가?
```

#### Case 3: 라이브러리 선택
```
질문: "React Native vs Flutter vs Kotlin Multiplatform,
2025년 기준 새 프로젝트에 어떤 것을 추천하시나요?
팀은 React 경험이 있고, iOS/Android 동시 출시 목표입니다."

평가 포인트:
- 각자 다른 추천을 하는가?
- 근거의 품질이 다른가?
```

#### Case 4: 레거시 마이그레이션
```
질문: "Java 8 + Spring Boot 2 프로젝트를
Java 21 + Spring Boot 3로 마이그레이션하려 합니다.
주의해야 할 점과 권장 순서를 알려주세요."

평가 포인트:
- 누락된 마이그레이션 포인트가 있는가?
- 실제 경험에서 나온 듯한 조언이 있는가?
```

#### Case 5: 디버깅/원인 분석
```
질문: [에러 로그 + 코드 첨부]
"프로덕션에서 간헐적으로 이 에러가 발생합니다.
원인과 해결책을 분석해주세요."

평가 포인트:
- 다양한 가설을 제시하는가?
- 한 AI의 잘못된 가설을 다른 AI가 반박하는가?
```

### 시뮬레이션 방법

```bash
# 1. 각 AI 웹/앱에서 동일 질문 입력
#    - ChatGPT (GPT-4)
#    - Claude (claude.ai)
#    - Gemini (gemini.google.com)

# 2. 응답을 나란히 놓고 비교

# 3. 평가표 작성
```

### 평가표 템플릿

| 항목 | ChatGPT | Claude | Gemini | 종합 판단 |
|------|---------|--------|--------|-----------|
| 핵심 추천 | | | | 일치/불일치 |
| 고유 인사이트 | | | | 있음/없음 |
| 누락 리스크 | | | | 발견 수 |
| 잘못된 정보 | | | | 있음/없음 |
| 확신도 | 높음/중간/낮음 | | | |

### 시뮬레이션 성공 기준

- 5개 케이스 중 **3개 이상**에서:
  - 한 AI가 놓친 포인트를 다른 AI가 발견
  - 또는 종합 시 단일 AI보다 명확히 풍부한 결과

---

## 3. 역사적 사례 재현

### 목적
과거 실제 기술 결정 사례를 AI에게 다시 질문하여, 당시보다 나은 결정을 제안하는지 확인

### 사례 수집 방법

1. **본인의 과거 프로젝트**에서:
   - "그때 다른 선택을 했으면 좋았을" 결정 3개
   - 결정 당시 컨텍스트 정리

2. **공개된 포스트모템**에서:
   - 유명 장애 사례 (예: GitHub 장애, AWS 장애)
   - "이렇게 하면 됐을 것" 분석이 있는 사례

### 평가 방법

```
입력: 당시 컨텍스트 + 질문 (정답은 숨김)
출력: AI들의 제안

비교:
- 실제로 한 결정 vs AI 제안
- 실제 결과(성공/실패) vs AI 제안의 예상 결과
```

---

## 4. Go/No-Go 결정 매트릭스

### 종합 점수표

| 검증 항목 | 가중치 | 점수 (0-10) | 가중 점수 |
|-----------|--------|-------------|-----------|
| 인터뷰: 사용 의향 | 30% | | |
| 인터뷰: 지불 의향 | 20% | | |
| 시뮬레이션: 차별적 인사이트 | 30% | | |
| 사례 재현: 개선된 결정 | 20% | | |
| **총점** | 100% | | **/10** |

### 결정 기준

| 총점 | 결정 | 다음 행동 |
|------|------|-----------|
| **7-10** | ✅ Go | v0.1 MVP 빌드 시작 |
| **5-6** | ⚠️ 조건부 | 타겟 문제 유형 좁히고 재검증 |
| **3-4** | 🔄 피벗 | 토론 → 비교 도구로 단순화 |
| **0-2** | ❌ No-Go | 프로젝트 중단 또는 완전 피벗 |

---

## 5. 즉시 실행 가능한 액션

### 오늘 할 수 있는 것

```bash
# 1. 시뮬레이션 Case 1 직접 실행
#    - ChatGPT, Claude, Gemini 웹에서 아키텍처 질문
#    - 15분 소요

# 2. 주변 개발자 1명에게 비공식 인터뷰
#    - 점심/커피 시간 활용
#    - 10분 소요

# 3. 결과 기록
echo "# Phase 0 검증 로그" > docs/validation-log.md
```

### 이번 주 목표

- [ ] 개발자 인터뷰 2명 완료
- [ ] 시뮬레이션 케이스 3개 실행
- [ ] 중간 판단: "계속 진행할 가치가 있는가?"

---

## 부록: 빠른 시뮬레이션 프롬프트

### 아키텍처 질문 (복붙용)

```
우리 팀은 5명의 백엔드 개발자로 구성되어 있고,
새로운 e-commerce 플랫폼을 처음부터 만들려고 합니다.

현재 고민:
- 마이크로서비스 vs 모놀리스 vs 모듈러 모놀리스
- 예상 트래픽: 출시 후 1년 내 MAU 50만, 3년 내 100만
- 팀 경험: Spring Boot 위주, K8s 경험 적음

질문:
1. 어떤 아키텍처를 추천하시나요?
2. 그 이유는 무엇인가요?
3. 이 선택의 가장 큰 리스크는?
4. 대안을 선택했을 때의 장점은?
```

### 보안 분석 질문 (복붙용)

```
다음 결제 처리 코드를 보안 관점에서 분석해주세요.

[코드 첨부]

질문:
1. 잠재적 보안 취약점은?
2. 각 취약점의 심각도 (Critical/High/Medium/Low)?
3. 수정 방안은?
4. 내가 놓쳤을 수 있는 다른 리스크는?
```
