# obora 기획서

## 프로젝트 비전

> **"혼자 결정하기 두려운 복잡한 문제"를 위한 비동기 AI 기술/설계 리뷰 위원회**
>
> 실시간 코딩 보조가 아닌, **리스크 감소와 블라인드 스팟 제거**에 초점을 맞춘 **심층 리뷰 리포트 생성기**

---

## 핵심 컨셉

### "Deep Review" (심층 리뷰)

```
기존: 개발자가 AI와 실시간으로 채팅하며 코딩 (속도 중심)
obora: 개발자가 복잡한 문제를 던져두면, 여러 AI가 검증 후 리포트 제출 (품질/안전 중심)
```

### 지원 대상 AI (API/헤드리스)

- Claude Code (논리/추론 강점)
- GitHub Copilot / Codex (코드 구현 강점)
- Gemini (긴 컨텍스트/검색 강점)
- 기타 API 제공 AI 도구들

### 워크플로우: 비동기 리포트

```
You: "이 아키텍처의 보안 취약점과 확장성 리스크를 분석해줘" (obora review --deep)

... (obora가 백그라운드에서 실행) ...

1. [Orchestrator]: 각 AI에게 독립적인 분석 요청 (편향 방지)
2. [Debate]: 서로의 분석에 대한 반박(Devil's Advocate) 유도
3. [Synthesis]: 합의된 사항과 여전히 엇갈리는 리스크 정리

→ 📋 최종 "설계 검증 리포트" 제공
```

---

## 핵심 가치

| 구분 | 일반 AI 코딩 도구 (Aider, Cursor) | obora |
|------|-------------------------------|-------|
| **목표** | 속도 (Faster Coding) | **안전 & 품질 (Risk Reduction)** |
| **방식** | 실시간 채팅 (Synchronous) | **비동기 리뷰 (Asynchronous)** |
| **산출물** | 코드 조각, 수정 사항 | **구조화된 검증 리포트** |
| **가치** | 생산성 향상 | **의사결정 오류 비용 최소화** |

---

## 협업 모드

### 1. Parallel (다각도 분석)
```
You → [Claude] / [Gemini] / [Codex] → 구조화된 비교 표
```
- 동시에 같은 질문을 던져 답변의 다양성 확보
- 각 모델의 "확신도"와 "근거"를 비교
- 용도: 라이브러리 선택, 기술 스택 비교

### 2. Orchestrated Debate (구조화된 토론)
```
Round 1: 독립 의견 수집 (Blind Review)
Round 2: 상호 반박 (Cross-Examination) - "Gemini는 Claude의 보안 지적을 반박해보라"
Round 3: 합의 및 잔존 리스크 도출
```
- 사회자(Orchestrator)가 적극적으로 개입하여 동조 편향(Sycophancy) 방지
- 용도: 아키텍처 설계, 보안 감사, 레거시 리팩토링 전략

### 3. Deep Review (심층 리뷰 리포트) ⭐ 핵심 MVP
```
복잡한 입력(코드베이스, 설계문서) → 밤새 토론(배경 작업) → 아침에 리포트 확인
```
- 사용자의 대기 시간(Latency) 스트레스 제거
- 충분한 시간을 들여 깊이 있는 분석 수행

---

## 사용 시나리오

### 1. 아키텍처 의사결정 (ADR 초안 작성)
```
You: "MSA로 전환하려는데, 우리 팀 규모(5명)에서 발생할 리스크는?"

→ obora가 다양한 관점(운영 복잡도, 배포 용이성 등)에서 격론 후
→ '조건부 추천' 리포트와 함께 '체크리스트' 제공
```

### 2. 보안/엣지케이스 점검
```
You: "이 결제 모듈 로직에서 놓친 엣지케이스가 있을까?"

→ 한 AI가 로직을 짤 때, 다른 AI는 '해커' 입장에서 공격 시나리오 제시
→ 방어 코드가 포함된 최종 수정안 제안
```

---

## 사용자 인터페이스

### 명령어

```bash
obora review <file>         # 가벼운 병렬 리뷰
obora review --deep <file>  # 심층 토론 리포트 생성 (시간 소요)
obora compare <question>    # 단순 모델별 답변 비교
```

### 화면 예시 (TUI/Report)

```
┌────────────────────────────────────────────────┐
│ 📋 obora Deep Review Report                    │
├────────────────────────────────────────────────┤
│                                                │
│ 🎯 결론 요약                                    │
│ "제안하신 구조는 확장성은 좋으나, 현재 인력으론   │
│ 운영 복잡도가 3배 증가할 위험이 있습니다."        │
│                                                │
│ ✅ 합의된 장점                                  │
│ - 서비스 간 결합도 감소                         │
│ - 배포 독립성 확보                              │
│                                                │
│ ⚠️ 주요 쟁점 (Disagreement)                     │
│ [Claude]: 트랜잭션 관리가 너무 복잡해짐 (우려)    │
│ [Gemini]: Saga 패턴으로 해결 가능 (낙관)         │
│ [Codex]: 구현 난이도 상, 러닝커브 높음 (중립)     │
│                                                │
│ 🛠️ 제안 사항                                    │
│ 1. 모듈러 모놀리스로 시작 (Claude/Codex 지지)    │
│ 2. 이벤트 버스 도입은 추후 고려                  │
│                                                │
└────────────────────────────────────────────────┘
```

---

## 가설 검증 프레임워크

### 핵심 가설 (검증 대상)

```
H0 (귀무가설): 멀티 AI 협업은 단일 최고 성능 AI 대비 의미 있는 차이가 없다
H1 (대립가설): 특정 유형의 문제에서 멀티 AI가 통계적으로 유의미한 개선을 보인다
```

### 검증 단계

#### Phase 0: 수동 검증 (빌드 전) ⭐ 최우선

**목표**: 코드 한 줄 쓰기 전에 가설의 가치 확인

| 방법 | 구체적 실행 | 성공 기준 |
|------|-------------|-----------|
| **개발자 인터뷰 (N=5)** | "중요 기술 결정 시 여러 AI에 물어본 경험?" | 3/5 이상 "해봤거나 하고 싶다" |
| **수동 시뮬레이션** | ChatGPT + Claude + Gemini 웹에서 동일 질문 → 수동 비교 | 명확한 차별적 인사이트 발견 |
| **역사적 사례 재현** | 과거 기술 의사결정 5건을 AI들에게 재질문 | 실제 결정보다 나은 대안 제시 여부 |

**Phase 0 결과 해석:**
- ✅ 통과: Phase 1 진행
- ⚠️ 미묘함: 타겟 문제 유형 좁히기
- ❌ 실패: 피벗 또는 중단

#### Phase 1: MVP 빌드 + 알파 테스트

**목표**: 최소 기능으로 실제 사용자 반응 측정

```bash
# MVP 범위: Parallel 비교 리포트만
obora compare "마이크로서비스 vs 모놀리스" --output report.md
```

| 측정 지표 | 방법 | 목표 |
|-----------|------|------|
| **설치 완료율** | 설치 시작 → 첫 실행 | > 70% |
| **재사용률** | 첫 주 내 2회 이상 사용 | > 30% |
| **NPS (추천 의향)** | 알파 사용자 설문 | > 30 |

#### Phase 2: 정량적 벤치마크

**목표**: "멀티 AI가 낫다"를 숫자로 증명

**실험 설계:**
```
데이터셋: 기술 의사결정 문제 50개
  - 아키텍처 설계 (15개)
  - 보안 취약점 분석 (15개)
  - 라이브러리/프레임워크 선택 (10개)
  - 레거시 리팩토링 전략 (10개)

비교군:
  A) Claude Opus 단독
  B) Claude + Gemini + Codex 병렬 (비교만)
  C) Claude + Gemini + Codex 토론 (Debate)

평가 지표:
  1. 누락 리스크 수 (전문가 평가)
  2. 제안 품질 점수 (1-5점, 블라인드 평가)
  3. 잘못된 확신 비율 ("확실하다"고 했는데 틀린 경우)
  4. 의사결정 후 수정 필요성 (시뮬레이션)
```

**통계적 유의성:**
- p < 0.05에서 B 또는 C가 A보다 우월해야 "가설 검증됨"
- 효과 크기(Cohen's d) > 0.5 필요 (실용적 의미)

### 세부 가설 분해

| ID | 가설 | 검증 방법 | 피벗 트리거 |
|----|------|-----------|-------------|
| H1 | 멀티 AI가 누락 리스크를 더 잘 발견 | 체크리스트 커버리지 비교 | 차이 < 10% |
| H2 | 토론이 병렬 비교보다 나은 결과 | B vs C 품질 비교 | 유의미한 차이 없음 |
| H3 | 사용자가 멀티 AI 결과를 더 신뢰 | 설문 + 실제 채택률 | 신뢰도 차이 없음 |
| H4 | 실제 의사결정 품질 향상 | 사후 롤백/버그율 추적 | 개선 없음 |

### 피벗 시나리오

**시나리오 1: "토론"의 가치가 없다면**
```
증거: H2 기각 (토론 ≈ 병렬 비교)
피벗: "AI 토론 도구" → "AI 응답 비교 도구"
장점: 더 단순한 가치 제안, 구현 복잡도 ↓
```

**시나리오 2: "멀티 AI" 자체의 가치가 없다면**
```
증거: H1 기각 (멀티 AI ≈ 단일 AI)
피벗:
  A) 모델 앙상블(투표) 기반 정확도 향상 연구
  B) AI 오케스트레이션 프레임워크 (개발자 도구)
  C) 프로젝트 중단
```

**시나리오 3: 특정 문제 유형에서만 가치 있다면**
```
증거: 아키텍처/보안에서만 유의미한 차이
피벗: 범용 도구 → "AI 보안 감사 도구" 또는 "AI 아키텍처 리뷰어"로 니치 집중
```

---

## 로드맵

### v0.0 - 가설 검증 (Phase 0) ⭐ 현재
- [x] `.dev/ask.ts` 프로토타입으로 토론 시뮬레이션
- [ ] 개발자 인터뷰 5명 진행
- [ ] 수동 시뮬레이션으로 가치 확인
- [ ] Go/No-Go 결정

### v0.1 - Proof of Value (Report)
- [ ] TUI 기반 입력 인터페이스
- [ ] **Parallel Review Mode**: 3개 모델 답변 단순 비교 기능
- [ ] **Structured Output**: Markdown 리포트 생성

### v0.2 - Orchestration
- [ ] **Debate Protocol**: 사회자(Orchestrator) 프롬프트 구현
- [ ] 동조 편향 방지 로직 (Blind Review 단계 추가)
- [ ] CLI에서 기존 구독(Claude/Gemini/Codex) 연동

### v0.3 - Deep Integration
- [ ] 코드베이스 컨텍스트 자동 수집
- [ ] Github PR 연동 (Bot 모드)

---

## 결론

obora는 더 빠른 코딩을 위한 도구가 아닙니다.
**더 현명한 엔지니어링 의사결정**을 돕는 **AI 기술 위원회**입니다.

```
"내가 짠 코드를 3명의 시니어 엔지니어가 밤새 리뷰해준다면?"
```

핵심 차별점: **Orchestrated Conflict** - 인위적인 반론과 검증을 통해 "집단 사고"를 방지하고 최적의 해를 찾습니다.
