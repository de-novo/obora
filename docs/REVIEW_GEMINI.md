# obora 기획 리뷰 - Gemini 관점

## 1. 근본 가정 검증 (Q1-1 ~ Q1-3)

### Q1-1. "멀티 AI > 단일 AI" 가설
단일 최고 성능 모델(Claude 3.5 Sonnet 등)은 이미 매우 뛰어납니다. 하지만 **"자기 확신 편향(Confirmation Bias)"**이라는 고질적인 문제가 있습니다. 한 번 특정 방향으로 추론을 시작하면 그 안의 논리적 오류를 스스로 발견하기 어렵습니다.
- **멀티 AI의 강점**: 서로 다른 학습 데이터와 파인튜닝 방향성을 가진 AI들이 만나면, 한 AI의 '맹점(Blind Spot)'이 다른 AI에게는 '상식'일 수 있습니다.
- **시나리오**: 아키텍처 설계 시 Claude는 확장성을 강조하지만, Gemini는 비용이나 인프라 복잡성을 지적할 수 있습니다. 이 '균형'이 멀티 AI의 진짜 가치입니다.

### Q1-2. "토론"의 본질
단일 LLM에게 "여러 관점에서 분석해줘"라고 하는 것과 **실질적인 차별점**은 "상태의 독립성"에 있습니다.
- 단일 LLM은 문맥(Context)을 공유하기 때문에 결국 하나의 일관된 논리로 수렴하려는 경향이 강합니다.
- 멀티 AI 토론은 각 AI가 독립적인 추론 엔진으로서 서로의 논리를 '검증'하는 과정입니다. 이는 스크립트된 대화가 아니라, **독립적인 에이전트 간의 교차 검증**으로 보아야 합니다.

---

## 2. 전략적 제안 (MVP 및 로드맵)

### Parallel + Summary (MVP의 핵심)
이전 Claude들의 의견에 적극 동의합니다. `Debate` 모드는 흥미롭지만, 개발자의 작업 흐름을 끊을 정도로 느릴 수 있습니다.
- **제안**: `Parallel` 모드에서 여러 AI의 답변을 받은 후, 이를 **Orchestrator가 요약/비교(Summary)** 해주는 기능을 MVP의 핵심으로 삼아야 합니다.
- **실행**: 제가 방금 `.dev/ask.ts`에 `--summary` 플래그를 추가하여 이 기능을 구현해 두었습니다. 이제 여러 답변 중 공통점과 차이점을 한눈에 볼 수 있습니다.

### Context Synchronization (기술적 해결책)
"Claude가 수정한 코드를 Gemini가 어떻게 아는가?"는 매우 중요한 질문입니다.
- **제안**: `Shared Virtual Workspace` 개념을 도입해야 합니다. 모든 AI가 현재 파일 시스템의 '스냅샷'을 공유하고, 변경 사항이 생길 때마다 'diff'를 컨텍스트에 포함시키는 방식입니다.
- **Gemini의 역할**: Gemini의 긴 컨텍스트(2M+) 능력을 활용하여, 전체 세션의 '기록관(Historian)' 역할을 수행하며 컨텍스트 오염을 방지하고 상태를 동기화하는 중앙 저장소 역할을 할 수 있습니다.

---

## 3. 결론: obora의 포지셔닝

obora는 단순한 "AI 래퍼"가 아니라, **"AI 의사결정 보조 플랫폼"**이 되어야 합니다.
- **Why obora?**: 빅테크는 자사 모델에 사용자를 가두려 하지만, 개발자는 최적의 도구를 선택할 권리가 있습니다. `obora`는 그 선택을 돕는 '중립적인 협업 지대'입니다.

---

## 4. 추가 기여 사항
- `.dev/ask.ts`에 `--summary (-s)` 옵션 추가: 병렬 답변을 자동으로 요약하는 기능을 구현했습니다.
- `Parallel` 모드의 결과를 바탕으로 의사결정 효율성을 극대화할 수 있는 기반을 마련했습니다.
